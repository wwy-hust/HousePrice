#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
URLæ•°æ®é‡‡é›†æ¥å£ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ•°æ®é‡‡é›†åŠŸèƒ½
"""

from data_collector import HousePriceDataCollector
from url_collector_api import collect_url_data
import pandas as pd

def example_1_basic_usage():
    """ç¤ºä¾‹1: åŸºæœ¬ä½¿ç”¨æ–¹æ³•"""
    print("=" * 60)
    print("ç¤ºä¾‹1: åŸºæœ¬ä½¿ç”¨æ–¹æ³•")
    print("=" * 60)
    
    # åˆ›å»ºæ•°æ®é‡‡é›†å™¨
    collector = HousePriceDataCollector()
    
    # é‡‡é›†å•ä¸ªURLçš„æ•°æ®
    url = "https://www.stats.gov.cn/sj/zxfb/202507/t20250715_1960403.html"
    description = "2025å¹´6æœˆä»½70ä¸ªå¤§ä¸­åŸå¸‚å•†å“ä½å®…é”€å”®ä»·æ ¼å˜åŠ¨æƒ…å†µ"
    date = "2025-07-15"
    
    print(f"æ­£åœ¨é‡‡é›†æ•°æ®...")
    print(f"URL: {url}")
    print(f"æè¿°: {description}")
    print(f"æ—¥æœŸ: {date}")
    
    success = collector.collect_single_url_data(url, description, date)
    
    if success:
        print("âœ… æ•°æ®é‡‡é›†æˆåŠŸï¼")
    else:
        print("âŒ æ•°æ®é‡‡é›†å¤±è´¥ï¼")

def example_2_batch_collection():
    """ç¤ºä¾‹2: æ‰¹é‡é‡‡é›†"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹2: æ‰¹é‡é‡‡é›†å¤šä¸ªURL")
    print("=" * 60)
    
    # åˆ›å»ºæ•°æ®é‡‡é›†å™¨
    collector = HousePriceDataCollector()
    
    # åŠ è½½URLåˆ—è¡¨
    url_df = collector.load_url_list()
    
    # åªé‡‡é›†å‰3ä¸ªURLä½œä¸ºç¤ºä¾‹
    sample_urls = url_df.head(3)
    
    print(f"å‡†å¤‡é‡‡é›† {len(sample_urls)} ä¸ªURLçš„æ•°æ®...")
    
    success_count = 0
    for index, row in sample_urls.iterrows():
        url = row['æ ‡é¢˜é“¾æ¥']
        description = row['æ ‡é¢˜']
        date = row['æ—¶é—´']
        
        print(f"\næ­£åœ¨é‡‡é›†ç¬¬ {index + 1} ä¸ªURL...")
        print(f"æè¿°: {description}")
        
        success = collector.collect_single_url_data(url, description, date)
        if success:
            success_count += 1
            print("âœ… é‡‡é›†æˆåŠŸ")
        else:
            print("âŒ é‡‡é›†å¤±è´¥")
    
    print(f"\næ‰¹é‡é‡‡é›†å®Œæˆï¼æˆåŠŸ: {success_count}/{len(sample_urls)}")

def example_3_api_usage():
    """ç¤ºä¾‹3: ä½¿ç”¨APIæ¥å£"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹3: ä½¿ç”¨APIæ¥å£")
    print("=" * 60)
    
    # ä½¿ç”¨APIæ¥å£é‡‡é›†æ•°æ®
    url = "https://www.stats.gov.cn/sj/zxfb/202506/t20250616_1960163.html"
    description = "2025å¹´5æœˆä»½æˆ¿ä»·æ•°æ®"
    date = "2025-06-16"
    
    print(f"ä½¿ç”¨APIæ¥å£é‡‡é›†æ•°æ®...")
    print(f"URL: {url}")
    
    success = collect_url_data(url, description, date)
    
    if success:
        print("âœ… APIé‡‡é›†æˆåŠŸï¼")
    else:
        print("âŒ APIé‡‡é›†å¤±è´¥ï¼")

def example_4_data_analysis():
    """ç¤ºä¾‹4: æ•°æ®åˆ†æç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹4: æ•°æ®åˆ†æç¤ºä¾‹")
    print("=" * 60)
    
    # åŠ è½½URLåˆ—è¡¨
    collector = HousePriceDataCollector()
    url_df = collector.load_url_list()
    
    print("URLåˆ—è¡¨ä¿¡æ¯:")
    print(f"æ€»URLæ•°é‡: {len(url_df)}")
    print(f"æ—¶é—´èŒƒå›´: {url_df['æ—¶é—´'].min()} åˆ° {url_df['æ—¶é—´'].max()}")
    
    # æŒ‰å¹´ä»½ç»Ÿè®¡
    url_df['å¹´ä»½'] = pd.to_datetime(url_df['æ—¶é—´']).dt.year
    yearly_count = url_df['å¹´ä»½'].value_counts().sort_index()
    
    print("\næŒ‰å¹´ä»½ç»Ÿè®¡:")
    for year, count in yearly_count.items():
        print(f"  {year}å¹´: {count} æ¡æ•°æ®")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ  æˆ¿ä»·æ•°æ®é‡‡é›†æ¥å£ä½¿ç”¨ç¤ºä¾‹")
    print("æœ¬ç¤ºä¾‹å°†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ•°æ®é‡‡é›†åŠŸèƒ½")
    
    try:
        # è¿è¡Œç¤ºä¾‹
        example_1_basic_usage()
        example_2_batch_collection()
        example_3_api_usage()
        example_4_data_analysis()
        
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ è¿è¡Œç¤ºä¾‹æ—¶å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main()
